import streamlit as st
import pandas as pd
import numpy as np
import joblib
import os
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
from danawaCrawler import DanawaCrawler
from danawaReviewPreprocessing import DanawaReviewPreprocessor
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.sequence import pad_sequences

# âœ… í•œê¸€ í°íŠ¸ ì„¤ì • (ìœˆë„ìš° ê¸°ì¤€)
plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="GPU ë¦¬ë·° ê°ì„± ë¶„ì„", layout="wide")
st.title("GPU ë¦¬ë·° ê°ì„± ë¶„ì„ ëŒ€ì‹œë³´ë“œ")

# ì‚¬ì´ë“œë°”
st.sidebar.title("ğŸ“Š í”„ë¡œì íŠ¸ ì†Œê°œ")
st.sidebar.markdown("ë‹¤ë‚˜ì™€ GPU ìƒí’ˆì˜ ë¦¬ë·°ë¥¼ ìˆ˜ì§‘í•˜ê³  ê°ì„± ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.")
st.sidebar.info("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ë©´ ë¦¬ë·° ìˆ˜ì§‘ â†’ ì „ì²˜ë¦¬ â†’ ê°ì„± ë¶„ì„ê¹Œì§€ ìë™ ì‹¤í–‰ë©ë‹ˆë‹¤.")

# ê²€ìƒ‰ì–´ ì…ë ¥
query = st.text_input("ğŸ” ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”", placeholder="ì˜ˆ: RTX 4070")
log_box = st.empty()

# ê²½ë¡œ
raw_path = "./data/temp/temp.csv"
pre_path = "./data/preprocessedReview.csv"
pred_path = "./data/predictedReview.csv"
model_path = "./model/sentiment_rnn_model.keras"
tokenizer_path = "./model/sentiment_tokenizer.pkl"

# ê°ì„± ì˜ˆì¸¡ í•¨ìˆ˜
def predict_sentiment(texts, model, tokenizer, max_len=100):
    sequences = tokenizer.texts_to_sequences(texts)
    X = pad_sequences(sequences, maxlen=max_len)
    preds = model.predict(X, verbose=0)
    labels = ['negative', 'neutral', 'positive']
    results = [labels[np.argmax(p)] for p in preds]
    probs = [float(np.max(p)) for p in preds]
    return results, probs

# ì „ì²´ ì‹¤í–‰ ë²„íŠ¼
if st.button("ğŸš€ ë¦¬ë·° ìˆ˜ì§‘ â†’ ì „ì²˜ë¦¬ â†’ ê°ì„± ë¶„ì„ ì‹œì‘"):
    if not query.strip():
        st.warning("â— ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        with st.spinner("1ï¸âƒ£ ë¦¬ë·° ìˆ˜ì§‘ ì¤‘ì…ë‹ˆë‹¤..."):
            try:
                crawler = DanawaCrawler(headless=True, logger=log_box.write)
                df_raw = crawler.crawl_top_k_products(query, top_k=5)
                crawler.quit()

                os.makedirs("./data/temp", exist_ok=True)
                df_raw.to_csv(raw_path, index=False, encoding="utf-8-sig")
                st.success(f"âœ… ë¦¬ë·° ìˆ˜ì§‘ ì™„ë£Œ! ({len(df_raw)}ê°œ)")
                st.dataframe(df_raw.head(5))
            except Exception as e:
                st.error(f"âŒ ë¦¬ë·° ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
                st.stop()

        with st.spinner("2ï¸âƒ£ ë¦¬ë·° ì „ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤..."):
            try:
                processor = DanawaReviewPreprocessor(logger=log_box.write)
                df_pre = processor.preprocess(raw_path, pre_path)
                st.success(f"âœ… ì „ì²˜ë¦¬ ì™„ë£Œ! ({len(df_pre)}ê°œ)")
                st.dataframe(df_pre.head(5))
            except Exception as e:
                st.error(f"âŒ ì „ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                st.stop()

        with st.spinner("3ï¸âƒ£ ê°ì„± ë¶„ì„ ì˜ˆì¸¡ ì¤‘ì…ë‹ˆë‹¤..."):
            try:
                model = load_model(model_path)
                tokenizer = joblib.load(tokenizer_path)

                if 'tokens' not in df_pre.columns:
                    from konlpy.tag import Okt
                    okt = Okt()
                    df_pre['tokens'] = df_pre['review'].apply(lambda x: ' '.join(okt.morphs(str(x))))

                preds, probs = predict_sentiment(df_pre['tokens'], model, tokenizer)
                df_pre['predicted'] = preds
                df_pre['confidence'] = probs
                df_pre.to_csv(pred_path, index=False, encoding="utf-8-sig")

                st.success("âœ… ê°ì„± ë¶„ì„ ì™„ë£Œ!")
                st.dataframe(df_pre[['review', 'predicted', 'confidence']])

                # ğŸ“Š ê°ì • ë¶„í¬ ì°¨íŠ¸
                st.subheader("ğŸ“Š ê°ì • ë¹„ìœ¨ ì°¨íŠ¸")
                fig, ax = plt.subplots()
                value_counts = df_pre['predicted'].value_counts().reindex(['positive', 'neutral', 'negative']).fillna(0)
                value_counts.plot(kind='bar', color=['green', 'gray', 'red'], ax=ax)
                ax.set_title("ê°ì„± ë¶„ì„ ê²°ê³¼ ë¶„í¬")
                ax.set_ylabel("ë¦¬ë·° ìˆ˜")
                ax.set_xticklabels(['ê¸ì •', 'ì¤‘ë¦½', 'ë¶€ì •'], rotation=0)
                st.pyplot(fig)

                # âœ… ê°ì •ë³„ ë¦¬ë·° ìˆ˜ í…ìŠ¤íŠ¸ë¡œ ì¶œë ¥
                st.markdown("#### ê°ì •ë³„ ë¦¬ë·° ê°œìˆ˜")
                st.markdown(f"""
                - ê¸ì •: {int(value_counts['positive'])}ê°œ  
                - ì¤‘ë¦½: {int(value_counts['neutral'])}ê°œ  
                - ë¶€ì •: {int(value_counts['negative'])}ê°œ
                """)

            except Exception as e:
                st.error(f"âŒ ê°ì„± ë¶„ì„ ì˜¤ë¥˜: {e}")
